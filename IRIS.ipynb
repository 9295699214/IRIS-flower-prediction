{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ev1rzcl-MQ5A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBobn-vEN8od",
        "outputId": "49113d49-4095-438e-a890-66bd95c3451a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Data/IRIS.csv')"
      ],
      "metadata": {
        "id": "BTN76gCGMbUi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nDJl5j5yPanr",
        "outputId": "48bb6901-5d3d-4d9a-a477-9d70600b9bc9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width      species\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2442f9fd-5a2c-4473-81c3-b05f227d4f6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2442f9fd-5a2c-4473-81c3-b05f227d4f6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2442f9fd-5a2c-4473-81c3-b05f227d4f6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2442f9fd-5a2c-4473-81c3-b05f227d4f6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = data.drop(['species'], axis = 1)\n",
        "label = data[['species']]\n"
      ],
      "metadata": {
        "id": "5eh8oTxuQ8pX"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = features.to_numpy()\n",
        "features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cane4K7LVZ11",
        "outputId": "8405f1a0-02a8-451e-e44e-591b5797554d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_new = np.insert(features, 0, 1, axis=1)\n",
        "features_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm0RyOXKV4z3",
        "outputId": "609ad90f-f7a0-472f-9779-5915474fc2a1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val = list(label['species'].unique())\n",
        "val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umCjay_pRTLc",
        "outputId": "a9cbd21e-5f3f-4a4a-e12c-49330ed4e5dc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoded_data = np.asarray(pd.get_dummies(label, columns = ['species']))"
      ],
      "metadata": {
        "id": "Rl-TtG-RSC2v"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label.drop(['species'], axis=1)\n",
        "label = one_hot_encoded_data"
      ],
      "metadata": {
        "id": "hEV9h282Svfs"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "weights =  np.random.rand(5,3)\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYMnoqnwT2iP",
        "outputId": "4569d1e2-ed14-4aed-c1d0-85a96dce9d94"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.37454012, 0.95071431, 0.73199394],\n",
              "       [0.59865848, 0.15601864, 0.15599452],\n",
              "       [0.05808361, 0.86617615, 0.60111501],\n",
              "       [0.70807258, 0.02058449, 0.96990985],\n",
              "       [0.83244264, 0.21233911, 0.18182497]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = np.dot(features_new,weights)\n",
        "z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf7-rk4UUJAR",
        "outputId": "ac06f0a1-45bb-47f8-e19f-91dc22596194"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LNhW1T9WSrc",
        "outputId": "09647192-bef6-4ca8-bfb8-230ddf5fa6f4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.78878117, 4.849312  , 5.02570732])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJAaFBaJWX2W",
        "outputId": "4da98904-8524-4737-e0f2-2434ba136102"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = np.exp(z[0])/ np.sum(np.exp(z[0]))\n",
        "y_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uJJvXoOW_jr",
        "outputId": "a3e6983e-ddbf-4342-e4d2-58e2455df702"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.30032304, 0.3190633 , 0.38061366])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymdZoOofXnml",
        "outputId": "f47ade9f-6f7b-4953-e8f9-58c93275c12b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwb1VuaIYYe4",
        "outputId": "2c108961-50d4-422e-d57b-0fe8c9126fee"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.37250406, 0.95296173, 0.73178258],\n",
              "       [0.58283796, 0.17029177, 0.15754191],\n",
              "       [0.05350014, 0.87172262, 0.600152  ],\n",
              "       [0.68995969, 0.03297883, 0.97562841],\n",
              "       [0.82562302, 0.21640149, 0.1845822 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = np.exp(np.dot(features_new,weights))\n",
        "num.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POGJZ9fvav7S",
        "outputId": "61148963-213f-492c-f977-034490c80983"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "den = np.sum(num, axis=1)"
      ],
      "metadata": {
        "id": "YTcP1g_UdDa6"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "den = den.reshape(den.shape[0],1)"
      ],
      "metadata": {
        "id": "kmqlNVEMex0b"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_hat = num/den"
      ],
      "metadata": {
        "id": "wKVRCXrdey0A"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label[1]*y_hat[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TqLzM3ugt0G",
        "outputId": "dbb7b20d-bf5f-42c7-ecc5-e68b4b3e5391"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.89296434, 0.        , 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat"
      ],
      "metadata": {
        "id": "NoM3FFy2fa8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Loss Function\n",
        "\n",
        "loss = -np.mean(np.sum(label*np.log(y_hat)))\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmOYVkMMf_0G",
        "outputId": "ed34a28d-0762-42d3-fbdc-ae06589775f7"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "320.8076054958709"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Backpropogation\n",
        "\n",
        "dw = 1/features_new.shape[0] * (np.dot(features_new.T, (y_hat - label) ))\n",
        "print(dw.shape)\n",
        "print(features_new.shape)\n",
        "print(y_hat.shape)\n",
        "print(weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwFaIctnijVq",
        "outputId": "de9b224e-fe79-4038-9349-cf71ff699faa"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 3)\n",
            "(150, 5)\n",
            "(150, 3)\n",
            "(5, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1\n",
        "weights-=alpha * dw"
      ],
      "metadata": {
        "id": "StLf0kv6kdyl"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sk4cHSDmNHy",
        "outputId": "8f92ad72-1bad-4dcf-ecb9-e223bfe75125"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.37250406, 0.95296173, 0.73178258],\n",
              "       [0.58283796, 0.17029177, 0.15754191],\n",
              "       [0.05350014, 0.87172262, 0.600152  ],\n",
              "       [0.68995969, 0.03297883, 0.97562841],\n",
              "       [0.82562302, 0.21640149, 0.1845822 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(label*np.log(y_hat), axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMFMYKPfo6FR",
        "outputId": "ab821078-e092-4bdc-d17f-bb3b2076d167"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-7.61103089e-04, -4.23224436e-03, -1.75895564e-03, -6.77496884e-03,\n",
              "       -6.21430890e-04, -6.27567937e-04, -1.62043723e-03, -1.82920625e-03,\n",
              "       -9.44832214e-03, -5.27057963e-03, -4.92984810e-04, -3.58798642e-03,\n",
              "       -4.91591302e-03, -1.96502962e-03, -3.20730753e-05, -3.95262122e-05,\n",
              "       -9.44086164e-05, -7.24284085e-04, -6.60690552e-04, -4.68267873e-04,\n",
              "       -3.15354823e-03, -6.03452283e-04, -1.39730270e-04, -4.97068156e-03,\n",
              "       -1.47737852e-02, -9.84224270e-03, -2.65881800e-03, -1.10514815e-03,\n",
              "       -9.32153246e-04, -7.26327374e-03, -8.88914241e-03, -1.10860330e-03,\n",
              "       -1.88295243e-04, -6.09528908e-05, -5.27057963e-03, -8.10683174e-04,\n",
              "       -3.17168989e-04, -5.27057963e-03, -4.35562156e-03, -1.65447856e-03,\n",
              "       -4.98776726e-04, -3.09120483e-02, -2.37705421e-03, -1.77858358e-03,\n",
              "       -2.95920917e-03, -4.45266259e-03, -7.90056666e-04, -3.12097091e-03,\n",
              "       -5.45081838e-04, -1.54295797e-03, -2.06303963e-03, -7.36301601e-03,\n",
              "       -1.25817207e-02, -6.44356812e-02, -3.10882816e-02, -7.01371568e-02,\n",
              "       -3.39395791e-02, -8.03603535e-03, -4.05000601e-03, -5.11472924e-02,\n",
              "       -1.04131977e-02, -1.63697253e-02, -2.37077995e-03, -7.03979888e-02,\n",
              "       -1.85272479e-02, -3.23035838e-03, -1.85322276e-01, -2.00429453e-03,\n",
              "       -4.02971155e-01, -4.26525603e-03, -8.83168345e-01, -4.55751403e-03,\n",
              "       -6.71643987e-01, -2.51211175e-02, -2.94307752e-03, -3.34270616e-03,\n",
              "       -1.55489281e-02, -2.29687981e-01, -7.06239379e-02, -1.11819422e-02,\n",
              "       -5.00278774e-03, -3.00278466e-03, -4.25133281e-03, -2.16156014e+00,\n",
              "       -3.43503599e-01, -2.45886950e-02, -9.15673659e-03, -3.33459078e-02,\n",
              "       -8.04116662e-03, -3.15198816e-02, -8.50764354e-02, -2.93145155e-02,\n",
              "       -4.94335126e-03, -6.78195982e-03, -3.03614263e-02, -4.88448271e-03,\n",
              "       -1.11836673e-02, -4.17119865e-03, -4.94864939e-02, -9.93812268e-03,\n",
              "       -4.67692931e-05, -7.53270150e-03, -7.43448944e-03, -1.30478325e-02,\n",
              "       -7.59493552e-04, -1.03293349e-03, -1.54719134e-02, -1.04329520e-02,\n",
              "       -4.10315883e-03, -1.97485413e-03, -2.46442148e-01, -2.11029171e-02,\n",
              "       -2.17278394e-02, -2.09721054e-03, -3.08110403e-04, -7.91150385e-03,\n",
              "       -6.35040958e-02, -8.38580772e-03, -1.58889537e-05, -6.73813679e-02,\n",
              "       -5.42324569e-03, -7.71578696e-03, -8.32227082e-04, -2.30011913e-01,\n",
              "       -1.62595478e-02, -1.06415901e-01, -3.72442715e-01, -3.32571953e-01,\n",
              "       -1.50032902e-03, -4.97053623e-01, -1.44322901e-02, -3.00497726e-01,\n",
              "       -7.34295908e-04, -7.45062892e-01, -3.63302060e-02, -5.02525441e-03,\n",
              "       -1.17001499e-03, -6.49967809e-02, -3.87624482e-01, -7.44060539e-02,\n",
              "       -1.54536021e-03, -8.74722417e-02, -7.53270150e-03, -1.31909656e-03,\n",
              "       -9.38672225e-04, -1.81436774e-02, -3.45230139e-02, -7.47196008e-02,\n",
              "       -4.87979709e-03, -6.52788865e-02])"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1\n",
        "np.random.seed(42)\n",
        "weights =  np.random.rand(5,3)\n",
        "for i in range(1000):\n",
        "  z = np.dot(features_new,weights)\n",
        "  num = np.exp(np.dot(features_new,weights))\n",
        "  den = np.sum(num, axis=1)\n",
        "  den = den.reshape(den.shape[0],1)\n",
        "  y_hat = num/den\n",
        "  loss = -np.mean(np.sum(label*np.log(y_hat), axis=1))\n",
        "  print('Epoch: '+str(i+1)+\" Loss: \"+str(loss))\n",
        "  dw = 1/features_new.shape[0] * (np.dot(features_new.T, (y_hat - label) ))\n",
        "  weights-=alpha * dw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuPieU1MmPA4",
        "outputId": "72579cf6-9e51-4451-dbea-aa35b8d6ed5e"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Loss: 2.138717369972473\n",
            "Epoch: 2 Loss: 1.690668163137116\n",
            "Epoch: 3 Loss: 1.555975299825662\n",
            "Epoch: 4 Loss: 1.4198174001142927\n",
            "Epoch: 5 Loss: 1.3130903120709756\n",
            "Epoch: 6 Loss: 1.2136167326220746\n",
            "Epoch: 7 Loss: 1.1337283921248626\n",
            "Epoch: 8 Loss: 1.0564937144243742\n",
            "Epoch: 9 Loss: 0.9959368354757258\n",
            "Epoch: 10 Loss: 0.9404930470317572\n",
            "Epoch: 11 Loss: 0.896323493157635\n",
            "Epoch: 12 Loss: 0.8634905522034996\n",
            "Epoch: 13 Loss: 0.8298091650556296\n",
            "Epoch: 14 Loss: 0.8181397554471763\n",
            "Epoch: 15 Loss: 0.787919498864809\n",
            "Epoch: 16 Loss: 0.7939473836593867\n",
            "Epoch: 17 Loss: 0.7609768421572891\n",
            "Epoch: 18 Loss: 0.7804126680203869\n",
            "Epoch: 19 Loss: 0.7407847442654796\n",
            "Epoch: 20 Loss: 0.7694100360783076\n",
            "Epoch: 21 Loss: 0.7229717395697309\n",
            "Epoch: 22 Loss: 0.7577548908818994\n",
            "Epoch: 23 Loss: 0.7066090699529519\n",
            "Epoch: 24 Loss: 0.745748592465384\n",
            "Epoch: 25 Loss: 0.6917802170272093\n",
            "Epoch: 26 Loss: 0.7341473865725541\n",
            "Epoch: 27 Loss: 0.6784317667278597\n",
            "Epoch: 28 Loss: 0.7232302000232318\n",
            "Epoch: 29 Loss: 0.6663606237655606\n",
            "Epoch: 30 Loss: 0.7129947820803163\n",
            "Epoch: 31 Loss: 0.6553472374636278\n",
            "Epoch: 32 Loss: 0.7033596077866705\n",
            "Epoch: 33 Loss: 0.6452044237520641\n",
            "Epoch: 34 Loss: 0.6942357973036826\n",
            "Epoch: 35 Loss: 0.6357818242554469\n",
            "Epoch: 36 Loss: 0.685544253307194\n",
            "Epoch: 37 Loss: 0.6269597981885344\n",
            "Epoch: 38 Loss: 0.6772179700519291\n",
            "Epoch: 39 Loss: 0.6186427485020078\n",
            "Epoch: 40 Loss: 0.669200994351947\n",
            "Epoch: 41 Loss: 0.6107536912560759\n",
            "Epoch: 42 Loss: 0.6614467708022477\n",
            "Epoch: 43 Loss: 0.6032300873830228\n",
            "Epoch: 44 Loss: 0.6539165366074561\n",
            "Epoch: 45 Loss: 0.5960206827402682\n",
            "Epoch: 46 Loss: 0.6465779316569346\n",
            "Epoch: 47 Loss: 0.5890831116177527\n",
            "Epoch: 48 Loss: 0.6394038456970279\n",
            "Epoch: 49 Loss: 0.582382069904347\n",
            "Epoch: 50 Loss: 0.6323714796671226\n",
            "Epoch: 51 Loss: 0.5758879124870592\n",
            "Epoch: 52 Loss: 0.6254615870643945\n",
            "Epoch: 53 Loss: 0.5695755677055092\n",
            "Epoch: 54 Loss: 0.6186578619145674\n",
            "Epoch: 55 Loss: 0.5634236902258315\n",
            "Epoch: 56 Loss: 0.6119464444063445\n",
            "Epoch: 57 Loss: 0.5574139945324077\n",
            "Epoch: 58 Loss: 0.6053155203944907\n",
            "Epoch: 59 Loss: 0.5515307263371853\n",
            "Epoch: 60 Loss: 0.5987549956852276\n",
            "Epoch: 61 Loss: 0.5457602401540377\n",
            "Epoch: 62 Loss: 0.5922562299750128\n",
            "Epoch: 63 Loss: 0.5400906592526362\n",
            "Epoch: 64 Loss: 0.5858118185114792\n",
            "Epoch: 65 Loss: 0.5345116000377504\n",
            "Epoch: 66 Loss: 0.5794154120787764\n",
            "Epoch: 67 Loss: 0.5290139471973108\n",
            "Epoch: 68 Loss: 0.5730615678973995\n",
            "Epoch: 69 Loss: 0.5235896691525748\n",
            "Epoch: 70 Loss: 0.5667456255818388\n",
            "Epoch: 71 Loss: 0.5182316657294458\n",
            "Epoch: 72 Loss: 0.5604636035120544\n",
            "Epoch: 73 Loss: 0.5129336417675506\n",
            "Epoch: 74 Loss: 0.5542121119226674\n",
            "Epoch: 75 Loss: 0.5076900017480983\n",
            "Epoch: 76 Loss: 0.5479882797565887\n",
            "Epoch: 77 Loss: 0.5024957615647045\n",
            "Epoch: 78 Loss: 0.5417896929138654\n",
            "Epoch: 79 Loss: 0.4973464743645504\n",
            "Epoch: 80 Loss: 0.5356143419876044\n",
            "Epoch: 81 Loss: 0.49223816800995945\n",
            "Epoch: 82 Loss: 0.5294605779444487\n",
            "Epoch: 83 Loss: 0.4871672921965318\n",
            "Epoch: 84 Loss: 0.5233270744983213\n",
            "Epoch: 85 Loss: 0.48213067364592377\n",
            "Epoch: 86 Loss: 0.5172127961593885\n",
            "Epoch: 87 Loss: 0.47712547809349765\n",
            "Epoch: 88 Loss: 0.5111169711279333\n",
            "Epoch: 89 Loss: 0.4721491780316914\n",
            "Epoch: 90 Loss: 0.5050390683548585\n",
            "Epoch: 91 Loss: 0.46719952536294246\n",
            "Epoch: 92 Loss: 0.4989787782143937\n",
            "Epoch: 93 Loss: 0.46227452827187276\n",
            "Epoch: 94 Loss: 0.49293599633619806\n",
            "Epoch: 95 Loss: 0.4573724317533853\n",
            "Epoch: 96 Loss: 0.48691081022806143\n",
            "Epoch: 97 Loss: 0.45249170133753797\n",
            "Epoch: 98 Loss: 0.48090348839044417\n",
            "Epoch: 99 Loss: 0.4476310096385019\n",
            "Epoch: 100 Loss: 0.4749144716830731\n",
            "Epoch: 101 Loss: 0.44278922542734234\n",
            "Epoch: 102 Loss: 0.4689443667539981\n",
            "Epoch: 103 Loss: 0.4379654049898626\n",
            "Epoch: 104 Loss: 0.46299394138473865\n",
            "Epoch: 105 Loss: 0.4331587855836507\n",
            "Epoch: 106 Loss: 0.4570641216428527\n",
            "Epoch: 107 Loss: 0.4283687808547393\n",
            "Epoch: 108 Loss: 0.45115599076656165\n",
            "Epoch: 109 Loss: 0.42359497811539504\n",
            "Epoch: 110 Loss: 0.4452707897358348\n",
            "Epoch: 111 Loss: 0.4188371374217165\n",
            "Epoch: 112 Loss: 0.4394099195111833\n",
            "Epoch: 113 Loss: 0.41409519242387494\n",
            "Epoch: 114 Loss: 0.43357494494573834\n",
            "Epoch: 115 Loss: 0.40936925299359445\n",
            "Epoch: 116 Loss: 0.4277676003980801\n",
            "Epoch: 117 Loss: 0.40465960966333947\n",
            "Epoch: 118 Loss: 0.4219897970926731\n",
            "Epoch: 119 Loss: 0.39996673993969656\n",
            "Epoch: 120 Loss: 0.41624363229108335\n",
            "Epoch: 121 Loss: 0.39529131657948446\n",
            "Epoch: 122 Loss: 0.41053140034957236\n",
            "Epoch: 123 Loss: 0.39063421794056796\n",
            "Epoch: 124 Loss: 0.40485560574573964\n",
            "Epoch: 125 Loss: 0.3859965405390509\n",
            "Epoch: 126 Loss: 0.3992189781564857\n",
            "Epoch: 127 Loss: 0.38137961395866926\n",
            "Epoch: 128 Loss: 0.39362448965876273\n",
            "Epoch: 129 Loss: 0.3767850182640559\n",
            "Epoch: 130 Loss: 0.3880753740992592\n",
            "Epoch: 131 Loss: 0.3722146040631852\n",
            "Epoch: 132 Loss: 0.3825751486338718\n",
            "Epoch: 133 Loss: 0.36767051534026524\n",
            "Epoch: 134 Loss: 0.37712763736539545\n",
            "Epoch: 135 Loss: 0.36315521513125937\n",
            "Epoch: 136 Loss: 0.37173699689911915\n",
            "Epoch: 137 Loss: 0.35867151403027964\n",
            "Epoch: 138 Loss: 0.3664077434794923\n",
            "Epoch: 139 Loss: 0.35422260138373424\n",
            "Epoch: 140 Loss: 0.36114478115280657\n",
            "Epoch: 141 Loss: 0.3498120788344919\n",
            "Epoch: 142 Loss: 0.355953430104729\n",
            "Epoch: 143 Loss: 0.34544399560130357\n",
            "Epoch: 144 Loss: 0.35083945392967736\n",
            "Epoch: 145 Loss: 0.34112288449729794\n",
            "Epoch: 146 Loss: 0.3458090840835428\n",
            "Epoch: 147 Loss: 0.33685379718166686\n",
            "Epoch: 148 Loss: 0.3408690391369106\n",
            "Epoch: 149 Loss: 0.3326423364780279\n",
            "Epoch: 150 Loss: 0.33602653567511376\n",
            "Epoch: 151 Loss: 0.3284946827644109\n",
            "Epoch: 152 Loss: 0.33128928679142056\n",
            "Epoch: 153 Loss: 0.3244176104402812\n",
            "Epoch: 154 Loss: 0.3266654831232644\n",
            "Epoch: 155 Loss: 0.3204184893279565\n",
            "Epoch: 156 Loss: 0.3221637503611012\n",
            "Epoch: 157 Loss: 0.3165052646336004\n",
            "Epoch: 158 Loss: 0.31779307624401326\n",
            "Epoch: 159 Loss: 0.3126864079032631\n",
            "Epoch: 160 Loss: 0.31356269944802556\n",
            "Epoch: 161 Loss: 0.30897083047303603\n",
            "Epoch: 162 Loss: 0.3094819527607296\n",
            "Epoch: 163 Loss: 0.305367750542233\n",
            "Epoch: 164 Loss: 0.30556005389272134\n",
            "Epoch: 165 Loss: 0.30188650561371566\n",
            "Epoch: 166 Loss: 0.30180583963362406\n",
            "Epoch: 167 Loss: 0.2985363041455347\n",
            "Epoch: 168 Loss: 0.2982274432375049\n",
            "Epoch: 169 Loss: 0.2953259143489956\n",
            "Epoch: 170 Loss: 0.29483192120326435\n",
            "Epoch: 171 Loss: 0.2922632945234908\n",
            "Epoch: 172 Loss: 0.29162484396852195\n",
            "Epoch: 173 Loss: 0.2893551781712229\n",
            "Epoch: 174 Loss: 0.2886098749012911\n",
            "Epoch: 175 Loss: 0.28660663782914964\n",
            "Epoch: 176 Loss: 0.28578837208264996\n",
            "Epoch: 177 Loss: 0.2840206627277739\n",
            "Epoch: 178 Loss: 0.28315905569583777\n",
            "Epoch: 179 Loss: 0.2815977948021103\n",
            "Epoch: 180 Loss: 0.2807177877888495\n",
            "Epoch: 181 Loss: 0.2793358723684283\n",
            "Epoch: 182 Loss: 0.27845750816929277\n",
            "Epoch: 183 Loss: 0.27722992806660246\n",
            "Epoch: 184 Loss: 0.27636835848711855\n",
            "Epoch: 185 Loss: 0.27527227555750927\n",
            "Epoch: 186 Loss: 0.27443800623475123\n",
            "Epoch: 187 Loss: 0.2734527981087741\n",
            "Epoch: 188 Loss: 0.27265215397137504\n",
            "Epoch: 189 Loss: 0.2717594244760463\n",
            "Epoch: 190 Loss: 0.2709951914451807\n",
            "Epoch: 191 Loss: 0.2701787487972674\n",
            "Epoch: 192 Loss: 0.26945092562699635\n",
            "Epoch: 193 Loss: 0.2686967282210256\n",
            "Epoch: 194 Loss: 0.26800331163105945\n",
            "Epoch: 195 Loss: 0.2672993805301228\n",
            "Epoch: 196 Loss: 0.266637109269064\n",
            "Epoch: 197 Loss: 0.26597340707304057\n",
            "Epoch: 198 Loss: 0.26533840509185114\n",
            "Epoch: 199 Loss: 0.26470668287102345\n",
            "Epoch: 200 Loss: 0.26409496422031337\n",
            "Epoch: 201 Loss: 0.2634885812064901\n",
            "Epoch: 202 Loss: 0.26289640393358316\n",
            "Epoch: 203 Loss: 0.2623101277753632\n",
            "Epoch: 204 Loss: 0.26173420567638367\n",
            "Epoch: 205 Loss: 0.2611640033522263\n",
            "Epoch: 206 Loss: 0.26060159941364297\n",
            "Epoch: 207 Loss: 0.2600444297124637\n",
            "Epoch: 208 Loss: 0.259493362299834\n",
            "Epoch: 209 Loss: 0.25894697996220045\n",
            "Epoch: 210 Loss: 0.25840557317588086\n",
            "Epoch: 211 Loss: 0.2578683526375578\n",
            "Epoch: 212 Loss: 0.25733535786279144\n",
            "Epoch: 213 Loss: 0.2568061416389068\n",
            "Epoch: 214 Loss: 0.25628065057065497\n",
            "Epoch: 215 Loss: 0.2557586243056136\n",
            "Epoch: 216 Loss: 0.25523998664195297\n",
            "Epoch: 217 Loss: 0.25472458024759825\n",
            "Epoch: 218 Loss: 0.25421233313175123\n",
            "Epoch: 219 Loss: 0.25370314554828904\n",
            "Epoch: 220 Loss: 0.2531969572977719\n",
            "Epoch: 221 Loss: 0.25269370132092234\n",
            "Epoch: 222 Loss: 0.2521933290694905\n",
            "Epoch: 223 Loss: 0.2516957923065548\n",
            "Epoch: 224 Loss: 0.25120105163892353\n",
            "Epoch: 225 Loss: 0.25070906980581165\n",
            "Epoch: 226 Loss: 0.2502198139022272\n",
            "Epoch: 227 Loss: 0.24973325314864767\n",
            "Epoch: 228 Loss: 0.24924935900103207\n",
            "Epoch: 229 Loss: 0.24876810457159285\n",
            "Epoch: 230 Loss: 0.24828946418595174\n",
            "Epoch: 231 Loss: 0.24781341335814697\n",
            "Epoch: 232 Loss: 0.2473399283146148\n",
            "Epoch: 233 Loss: 0.2468689861197125\n",
            "Epoch: 234 Loss: 0.2464005643023497\n",
            "Epoch: 235 Loss: 0.24593464099501644\n",
            "Epoch: 236 Loss: 0.24547119467200085\n",
            "Epoch: 237 Loss: 0.24501020426293066\n",
            "Epoch: 238 Loss: 0.24455164897849405\n",
            "Epoch: 239 Loss: 0.24409550839314573\n",
            "Epoch: 240 Loss: 0.2436417623319882\n",
            "Epoch: 241 Loss: 0.24319039092731937\n",
            "Epoch: 242 Loss: 0.24274137454601344\n",
            "Epoch: 243 Loss: 0.24229469382641136\n",
            "Epoch: 244 Loss: 0.24185032963176573\n",
            "Epoch: 245 Loss: 0.24140826307324076\n",
            "Epoch: 246 Loss: 0.2409684754798611\n",
            "Epoch: 247 Loss: 0.24053094841207667\n",
            "Epoch: 248 Loss: 0.24009566364206403\n",
            "Epoch: 249 Loss: 0.2396626031610736\n",
            "Epoch: 250 Loss: 0.23923174916618953\n",
            "Epoch: 251 Loss: 0.23880308406368858\n",
            "Epoch: 252 Loss: 0.23837659045981846\n",
            "Epoch: 253 Loss: 0.2379522511616665\n",
            "Epoch: 254 Loss: 0.23753004917043938\n",
            "Epoch: 255 Loss: 0.23710996768082254\n",
            "Epoch: 256 Loss: 0.2366919900758236\n",
            "Epoch: 257 Loss: 0.23627609992525056\n",
            "Epoch: 258 Loss: 0.23586228098154355\n",
            "Epoch: 259 Loss: 0.23545051717776508\n",
            "Epoch: 260 Loss: 0.2350407926240669\n",
            "Epoch: 261 Loss: 0.2346330916054357\n",
            "Epoch: 262 Loss: 0.23422739857857952\n",
            "Epoch: 263 Loss: 0.2338236981695734\n",
            "Epoch: 264 Loss: 0.23342197517103594\n",
            "Epoch: 265 Loss: 0.23302221453975885\n",
            "Epoch: 266 Loss: 0.2326244013940942\n",
            "Epoch: 267 Loss: 0.232228521011617\n",
            "Epoch: 268 Loss: 0.23183455882667264\n",
            "Epoch: 269 Loss: 0.2314425004280995\n",
            "Epoch: 270 Loss: 0.23105233155690635\n",
            "Epoch: 271 Loss: 0.230664038104066\n",
            "Epoch: 272 Loss: 0.23027760610830522\n",
            "Epoch: 273 Loss: 0.22989302175397464\n",
            "Epoch: 274 Loss: 0.22951027136893656\n",
            "Epoch: 275 Loss: 0.2291293414225134\n",
            "Epoch: 276 Loss: 0.2287502185234637\n",
            "Epoch: 277 Loss: 0.22837288941800812\n",
            "Epoch: 278 Loss: 0.2279973409878871\n",
            "Epoch: 279 Loss: 0.22762356024846137\n",
            "Epoch: 280 Loss: 0.22725153434684586\n",
            "Epoch: 281 Loss: 0.22688125056008185\n",
            "Epoch: 282 Loss: 0.2265126962933426\n",
            "Epoch: 283 Loss: 0.22614585907817455\n",
            "Epoch: 284 Loss: 0.22578072657076992\n",
            "Epoch: 285 Loss: 0.2254172865502729\n",
            "Epoch: 286 Loss: 0.2250555269171172\n",
            "Epoch: 287 Loss: 0.22469543569139433\n",
            "Epoch: 288 Loss: 0.22433700101125173\n",
            "Epoch: 289 Loss: 0.22398021113132008\n",
            "Epoch: 290 Loss: 0.2236250544211693\n",
            "Epoch: 291 Loss: 0.22327151936379258\n",
            "Epoch: 292 Loss: 0.2229195945541172\n",
            "Epoch: 293 Loss: 0.22256926869754223\n",
            "Epoch: 294 Loss: 0.22222053060850167\n",
            "Epoch: 295 Loss: 0.2218733692090533\n",
            "Epoch: 296 Loss: 0.22152777352749192\n",
            "Epoch: 297 Loss: 0.22118373269698674\n",
            "Epoch: 298 Loss: 0.22084123595424282\n",
            "Epoch: 299 Loss: 0.22050027263818417\n",
            "Epoch: 300 Loss: 0.22016083218866106\n",
            "Epoch: 301 Loss: 0.21982290414517755\n",
            "Epoch: 302 Loss: 0.21948647814564196\n",
            "Epoch: 303 Loss: 0.2191515439251377\n",
            "Epoch: 304 Loss: 0.218818091314714\n",
            "Epoch: 305 Loss: 0.2184861102401976\n",
            "Epoch: 306 Loss: 0.21815559072102383\n",
            "Epoch: 307 Loss: 0.21782652286908666\n",
            "Epoch: 308 Loss: 0.21749889688760726\n",
            "Epoch: 309 Loss: 0.21717270307002187\n",
            "Epoch: 310 Loss: 0.21684793179888628\n",
            "Epoch: 311 Loss: 0.21652457354479926\n",
            "Epoch: 312 Loss: 0.2162026188653419\n",
            "Epoch: 313 Loss: 0.21588205840403485\n",
            "Epoch: 314 Loss: 0.21556288288931158\n",
            "Epoch: 315 Loss: 0.21524508313350738\n",
            "Epoch: 316 Loss: 0.21492865003186504\n",
            "Epoch: 317 Loss: 0.21461357456155525\n",
            "Epoch: 318 Loss: 0.21429984778071262\n",
            "Epoch: 319 Loss: 0.21398746082748613\n",
            "Epoch: 320 Loss: 0.21367640491910472\n",
            "Epoch: 321 Loss: 0.21336667135095658\n",
            "Epoch: 322 Loss: 0.21305825149568255\n",
            "Epoch: 323 Loss: 0.21275113680228352\n",
            "Epoch: 324 Loss: 0.2124453187952407\n",
            "Epoch: 325 Loss: 0.2121407890736496\n",
            "Epoch: 326 Loss: 0.21183753931036672\n",
            "Epoch: 327 Loss: 0.2115355612511686\n",
            "Epoch: 328 Loss: 0.21123484671392348\n",
            "Epoch: 329 Loss: 0.21093538758777575\n",
            "Epoch: 330 Loss: 0.21063717583234082\n",
            "Epoch: 331 Loss: 0.21034020347691354\n",
            "Epoch: 332 Loss: 0.21004446261968635\n",
            "Epoch: 333 Loss: 0.2097499454269802\n",
            "Epoch: 334 Loss: 0.20945664413248535\n",
            "Epoch: 335 Loss: 0.20916455103651396\n",
            "Epoch: 336 Loss: 0.20887365850526257\n",
            "Epoch: 337 Loss: 0.2085839589700856\n",
            "Epoch: 338 Loss: 0.2082954449267788\n",
            "Epoch: 339 Loss: 0.20800810893487257\n",
            "Epoch: 340 Loss: 0.2077219436169359\n",
            "Epoch: 341 Loss: 0.20743694165788937\n",
            "Epoch: 342 Loss: 0.2071530958043281\n",
            "Epoch: 343 Loss: 0.2068703988638532\n",
            "Epoch: 344 Loss: 0.20658884370441422\n",
            "Epoch: 345 Loss: 0.2063084232536584\n",
            "Epoch: 346 Loss: 0.2060291304982907\n",
            "Epoch: 347 Loss: 0.20575095848344138\n",
            "Epoch: 348 Loss: 0.2054739003120426\n",
            "Epoch: 349 Loss: 0.2051979491442137\n",
            "Epoch: 350 Loss: 0.204923098196654\n",
            "Epoch: 351 Loss: 0.2046493407420445\n",
            "Epoch: 352 Loss: 0.20437667010845734\n",
            "Epoch: 353 Loss: 0.20410507967877264\n",
            "Epoch: 354 Loss: 0.2038345628901041\n",
            "Epoch: 355 Loss: 0.2035651132332312\n",
            "Epoch: 356 Loss: 0.20329672425203918\n",
            "Epoch: 357 Loss: 0.20302938954296687\n",
            "Epoch: 358 Loss: 0.2027631027544608\n",
            "Epoch: 359 Loss: 0.20249785758643787\n",
            "Epoch: 360 Loss: 0.2022336477897527\n",
            "Epoch: 361 Loss: 0.20197046716567466\n",
            "Epoch: 362 Loss: 0.2017083095653693\n",
            "Epoch: 363 Loss: 0.20144716888938782\n",
            "Epoch: 364 Loss: 0.20118703908716257\n",
            "Epoch: 365 Loss: 0.20092791415650904\n",
            "Epoch: 366 Loss: 0.20066978814313421\n",
            "Epoch: 367 Loss: 0.20041265514015114\n",
            "Epoch: 368 Loss: 0.2001565092876\n",
            "Epoch: 369 Loss: 0.1999013447719743\n",
            "Epoch: 370 Loss: 0.19964715582575418\n",
            "Epoch: 371 Loss: 0.19939393672694444\n",
            "Epoch: 372 Loss: 0.19914168179861938\n",
            "Epoch: 373 Loss: 0.19889038540847237\n",
            "Epoch: 374 Loss: 0.19864004196837207\n",
            "Epoch: 375 Loss: 0.1983906459339225\n",
            "Epoch: 376 Loss: 0.1981421918040307\n",
            "Epoch: 377 Loss: 0.19789467412047757\n",
            "Epoch: 378 Loss: 0.19764808746749546\n",
            "Epoch: 379 Loss: 0.1974024264713505\n",
            "Epoch: 380 Loss: 0.19715768579992965\n",
            "Epoch: 381 Loss: 0.196913860162333\n",
            "Epoch: 382 Loss: 0.19667094430847143\n",
            "Epoch: 383 Loss: 0.1964289330286683\n",
            "Epoch: 384 Loss: 0.19618782115326677\n",
            "Epoch: 385 Loss: 0.19594760355224092\n",
            "Epoch: 386 Loss: 0.19570827513481312\n",
            "Epoch: 387 Loss: 0.19546983084907354\n",
            "Epoch: 388 Loss: 0.19523226568160656\n",
            "Epoch: 389 Loss: 0.19499557465712017\n",
            "Epoch: 390 Loss: 0.1947597528380804\n",
            "Epoch: 391 Loss: 0.19452479532434974\n",
            "Epoch: 392 Loss: 0.19429069725283002\n",
            "Epoch: 393 Loss: 0.19405745379710923\n",
            "Epoch: 394 Loss: 0.19382506016711298\n",
            "Epoch: 395 Loss: 0.1935935116087596\n",
            "Epoch: 396 Loss: 0.19336280340361908\n",
            "Epoch: 397 Loss: 0.19313293086857647\n",
            "Epoch: 398 Loss: 0.19290388935549926\n",
            "Epoch: 399 Loss: 0.19267567425090779\n",
            "Epoch: 400 Loss: 0.19244828097565034\n",
            "Epoch: 401 Loss: 0.19222170498458138\n",
            "Epoch: 402 Loss: 0.19199594176624388\n",
            "Epoch: 403 Loss: 0.19177098684255514\n",
            "Epoch: 404 Loss: 0.19154683576849624\n",
            "Epoch: 405 Loss: 0.19132348413180433\n",
            "Epoch: 406 Loss: 0.19110092755267005\n",
            "Epoch: 407 Loss: 0.1908791616834366\n",
            "Epoch: 408 Loss: 0.19065818220830322\n",
            "Epoch: 409 Loss: 0.19043798484303187\n",
            "Epoch: 410 Loss: 0.19021856533465684\n",
            "Epoch: 411 Loss: 0.18999991946119843\n",
            "Epoch: 412 Loss: 0.18978204303137847\n",
            "Epoch: 413 Loss: 0.18956493188434068\n",
            "Epoch: 414 Loss: 0.18934858188937284\n",
            "Epoch: 415 Loss: 0.18913298894563224\n",
            "Epoch: 416 Loss: 0.18891814898187542\n",
            "Epoch: 417 Loss: 0.18870405795618878\n",
            "Epoch: 418 Loss: 0.1884907118557241\n",
            "Epoch: 419 Loss: 0.18827810669643563\n",
            "Epoch: 420 Loss: 0.18806623852282128\n",
            "Epoch: 421 Loss: 0.18785510340766523\n",
            "Epoch: 422 Loss: 0.18764469745178475\n",
            "Epoch: 423 Loss: 0.18743501678377844\n",
            "Epoch: 424 Loss: 0.18722605755977886\n",
            "Epoch: 425 Loss: 0.18701781596320588\n",
            "Epoch: 426 Loss: 0.18681028820452444\n",
            "Epoch: 427 Loss: 0.18660347052100382\n",
            "Epoch: 428 Loss: 0.18639735917648018\n",
            "Epoch: 429 Loss: 0.18619195046112105\n",
            "Epoch: 430 Loss: 0.185987240691193\n",
            "Epoch: 431 Loss: 0.18578322620883103\n",
            "Epoch: 432 Loss: 0.1855799033818114\n",
            "Epoch: 433 Loss: 0.18537726860332607\n",
            "Epoch: 434 Loss: 0.1851753182917597\n",
            "Epoch: 435 Loss: 0.1849740488904693\n",
            "Epoch: 436 Loss: 0.18477345686756624\n",
            "Epoch: 437 Loss: 0.18457353871569995\n",
            "Epoch: 438 Loss: 0.1843742909518446\n",
            "Epoch: 439 Loss: 0.18417571011708792\n",
            "Epoch: 440 Loss: 0.18397779277642184\n",
            "Epoch: 441 Loss: 0.1837805355185356\n",
            "Epoch: 442 Loss: 0.183583934955611\n",
            "Epoch: 443 Loss: 0.1833879877231199\n",
            "Epoch: 444 Loss: 0.1831926904796239\n",
            "Epoch: 445 Loss: 0.18299803990657532\n",
            "Epoch: 446 Loss: 0.18280403270812165\n",
            "Epoch: 447 Loss: 0.18261066561091033\n",
            "Epoch: 448 Loss: 0.18241793536389742\n",
            "Epoch: 449 Loss: 0.1822258387381566\n",
            "Epoch: 450 Loss: 0.18203437252669113\n",
            "Epoch: 451 Loss: 0.18184353354424723\n",
            "Epoch: 452 Loss: 0.18165331862712975\n",
            "Epoch: 453 Loss: 0.18146372463301955\n",
            "Epoch: 454 Loss: 0.1812747484407927\n",
            "Epoch: 455 Loss: 0.1810863869503414\n",
            "Epoch: 456 Loss: 0.18089863708239734\n",
            "Epoch: 457 Loss: 0.18071149577835613\n",
            "Epoch: 458 Loss: 0.1805249600001038\n",
            "Epoch: 459 Loss: 0.18033902672984511\n",
            "Epoch: 460 Loss: 0.18015369296993355\n",
            "Epoch: 461 Loss: 0.17996895574270308\n",
            "Epoch: 462 Loss: 0.17978481209030142\n",
            "Epoch: 463 Loss: 0.1796012590745254\n",
            "Epoch: 464 Loss: 0.17941829377665727\n",
            "Epoch: 465 Loss: 0.17923591329730346\n",
            "Epoch: 466 Loss: 0.17905411475623423\n",
            "Epoch: 467 Loss: 0.178872895292226\n",
            "Epoch: 468 Loss: 0.17869225206290315\n",
            "Epoch: 469 Loss: 0.17851218224458398\n",
            "Epoch: 470 Loss: 0.17833268303212654\n",
            "Epoch: 471 Loss: 0.1781537516387763\n",
            "Epoch: 472 Loss: 0.17797538529601556\n",
            "Epoch: 473 Loss: 0.1777975812534141\n",
            "Epoch: 474 Loss: 0.17762033677848177\n",
            "Epoch: 475 Loss: 0.1774436491565216\n",
            "Epoch: 476 Loss: 0.17726751569048543\n",
            "Epoch: 477 Loss: 0.17709193370083043\n",
            "Epoch: 478 Loss: 0.1769169005253767\n",
            "Epoch: 479 Loss: 0.17674241351916703\n",
            "Epoch: 480 Loss: 0.17656847005432724\n",
            "Epoch: 481 Loss: 0.1763950675199286\n",
            "Epoch: 482 Loss: 0.17622220332185098\n",
            "Epoch: 483 Loss: 0.17604987488264745\n",
            "Epoch: 484 Loss: 0.17587807964141097\n",
            "Epoch: 485 Loss: 0.17570681505364105\n",
            "Epoch: 486 Loss: 0.17553607859111262\n",
            "Epoch: 487 Loss: 0.17536586774174573\n",
            "Epoch: 488 Loss: 0.17519618000947712\n",
            "Epoch: 489 Loss: 0.1750270129141321\n",
            "Epoch: 490 Loss: 0.17485836399129848\n",
            "Epoch: 491 Loss: 0.17469023079220108\n",
            "Epoch: 492 Loss: 0.1745226108835781\n",
            "Epoch: 493 Loss: 0.1743555018475577\n",
            "Epoch: 494 Loss: 0.174188901281537\n",
            "Epoch: 495 Loss: 0.1740228067980612\n",
            "Epoch: 496 Loss: 0.17385721602470428\n",
            "Epoch: 497 Loss: 0.17369212660395078\n",
            "Epoch: 498 Loss: 0.1735275361930786\n",
            "Epoch: 499 Loss: 0.1733634424640432\n",
            "Epoch: 500 Loss: 0.17319984310336264\n",
            "Epoch: 501 Loss: 0.17303673581200338\n",
            "Epoch: 502 Loss: 0.17287411830526808\n",
            "Epoch: 503 Loss: 0.17271198831268356\n",
            "Epoch: 504 Loss: 0.1725503435778899\n",
            "Epoch: 505 Loss: 0.17238918185853158\n",
            "Epoch: 506 Loss: 0.17222850092614783\n",
            "Epoch: 507 Loss: 0.17206829856606595\n",
            "Epoch: 508 Loss: 0.17190857257729425\n",
            "Epoch: 509 Loss: 0.1717493207724164\n",
            "Epoch: 510 Loss: 0.17159054097748708\n",
            "Epoch: 511 Loss: 0.1714322310319281\n",
            "Epoch: 512 Loss: 0.17127438878842569\n",
            "Epoch: 513 Loss: 0.17111701211282895\n",
            "Epoch: 514 Loss: 0.1709600988840486\n",
            "Epoch: 515 Loss: 0.1708036469939577\n",
            "Epoch: 516 Loss: 0.17064765434729207\n",
            "Epoch: 517 Loss: 0.1704921188615525\n",
            "Epoch: 518 Loss: 0.1703370384669078\n",
            "Epoch: 519 Loss: 0.1701824111060979\n",
            "Epoch: 520 Loss: 0.17002823473433903\n",
            "Epoch: 521 Loss: 0.16987450731922896\n",
            "Epoch: 522 Loss: 0.1697212268406531\n",
            "Epoch: 523 Loss: 0.16956839129069198\n",
            "Epoch: 524 Loss: 0.16941599867352905\n",
            "Epoch: 525 Loss: 0.1692640470053598\n",
            "Epoch: 526 Loss: 0.1691125343143012\n",
            "Epoch: 527 Loss: 0.1689614586403021\n",
            "Epoch: 528 Loss: 0.16881081803505463\n",
            "Epoch: 529 Loss: 0.16866061056190626\n",
            "Epoch: 530 Loss: 0.16851083429577288\n",
            "Epoch: 531 Loss: 0.1683614873230519\n",
            "Epoch: 532 Loss: 0.16821256774153742\n",
            "Epoch: 533 Loss: 0.16806407366033485\n",
            "Epoch: 534 Loss: 0.16791600319977698\n",
            "Epoch: 535 Loss: 0.16776835449134092\n",
            "Epoch: 536 Loss: 0.1676211256775649\n",
            "Epoch: 537 Loss: 0.16747431491196743\n",
            "Epoch: 538 Loss: 0.16732792035896538\n",
            "Epoch: 539 Loss: 0.16718194019379382\n",
            "Epoch: 540 Loss: 0.16703637260242643\n",
            "Epoch: 541 Loss: 0.1668912157814965\n",
            "Epoch: 542 Loss: 0.1667464679382186\n",
            "Epoch: 543 Loss: 0.16660212729031104\n",
            "Epoch: 544 Loss: 0.1664581920659188\n",
            "Epoch: 545 Loss: 0.1663146605035377\n",
            "Epoch: 546 Loss: 0.1661715308519383\n",
            "Epoch: 547 Loss: 0.1660288013700915\n",
            "Epoch: 548 Loss: 0.16588647032709378\n",
            "Epoch: 549 Loss: 0.16574453600209402\n",
            "Epoch: 550 Loss: 0.16560299668422063\n",
            "Epoch: 551 Loss: 0.16546185067250854\n",
            "Epoch: 552 Loss: 0.16532109627582828\n",
            "Epoch: 553 Loss: 0.16518073181281437\n",
            "Epoch: 554 Loss: 0.16504075561179518\n",
            "Epoch: 555 Loss: 0.16490116601072308\n",
            "Epoch: 556 Loss: 0.16476196135710472\n",
            "Epoch: 557 Loss: 0.164623140007933\n",
            "Epoch: 558 Loss: 0.1644847003296186\n",
            "Epoch: 559 Loss: 0.16434664069792282\n",
            "Epoch: 560 Loss: 0.1642089594978903\n",
            "Epoch: 561 Loss: 0.16407165512378297\n",
            "Epoch: 562 Loss: 0.16393472597901437\n",
            "Epoch: 563 Loss: 0.16379817047608405\n",
            "Epoch: 564 Loss: 0.1636619870365133\n",
            "Epoch: 565 Loss: 0.16352617409078113\n",
            "Epoch: 566 Loss: 0.16339073007826024\n",
            "Epoch: 567 Loss: 0.16325565344715456\n",
            "Epoch: 568 Loss: 0.1631209426544365\n",
            "Epoch: 569 Loss: 0.1629865961657851\n",
            "Epoch: 570 Loss: 0.1628526124555245\n",
            "Epoch: 571 Loss: 0.16271899000656304\n",
            "Epoch: 572 Loss: 0.16258572731033336\n",
            "Epoch: 573 Loss: 0.16245282286673166\n",
            "Epoch: 574 Loss: 0.16232027518405917\n",
            "Epoch: 575 Loss: 0.16218808277896263\n",
            "Epoch: 576 Loss: 0.16205624417637648\n",
            "Epoch: 577 Loss: 0.16192475790946453\n",
            "Epoch: 578 Loss: 0.16179362251956267\n",
            "Epoch: 579 Loss: 0.16166283655612224\n",
            "Epoch: 580 Loss: 0.16153239857665297\n",
            "Epoch: 581 Loss: 0.16140230714666784\n",
            "Epoch: 582 Loss: 0.16127256083962663\n",
            "Epoch: 583 Loss: 0.16114315823688175\n",
            "Epoch: 584 Loss: 0.16101409792762283\n",
            "Epoch: 585 Loss: 0.16088537850882337\n",
            "Epoch: 586 Loss: 0.16075699858518633\n",
            "Epoch: 587 Loss: 0.1606289567690916\n",
            "Epoch: 588 Loss: 0.16050125168054247\n",
            "Epoch: 589 Loss: 0.1603738819471136\n",
            "Epoch: 590 Loss: 0.16024684620389915\n",
            "Epoch: 591 Loss: 0.16012014309346131\n",
            "Epoch: 592 Loss: 0.15999377126577888\n",
            "Epoch: 593 Loss: 0.1598677293781966\n",
            "Epoch: 594 Loss: 0.15974201609537558\n",
            "Epoch: 595 Loss: 0.15961663008924235\n",
            "Epoch: 596 Loss: 0.15949157003894052\n",
            "Epoch: 597 Loss: 0.15936683463078077\n",
            "Epoch: 598 Loss: 0.15924242255819307\n",
            "Epoch: 599 Loss: 0.15911833252167773\n",
            "Epoch: 600 Loss: 0.1589945632287578\n",
            "Epoch: 601 Loss: 0.15887111339393192\n",
            "Epoch: 602 Loss: 0.15874798173862673\n",
            "Epoch: 603 Loss: 0.1586251669911504\n",
            "Epoch: 604 Loss: 0.1585026678866464\n",
            "Epoch: 605 Loss: 0.1583804831670474\n",
            "Epoch: 606 Loss: 0.15825861158102955\n",
            "Epoch: 607 Loss: 0.15813705188396782\n",
            "Epoch: 608 Loss: 0.15801580283789027\n",
            "Epoch: 609 Loss: 0.1578948632114346\n",
            "Epoch: 610 Loss: 0.15777423177980318\n",
            "Epoch: 611 Loss: 0.1576539073247195\n",
            "Epoch: 612 Loss: 0.15753388863438497\n",
            "Epoch: 613 Loss: 0.1574141745034354\n",
            "Epoch: 614 Loss: 0.15729476373289883\n",
            "Epoch: 615 Loss: 0.15717565513015266\n",
            "Epoch: 616 Loss: 0.1570568475088817\n",
            "Epoch: 617 Loss: 0.15693833968903645\n",
            "Epoch: 618 Loss: 0.15682013049679178\n",
            "Epoch: 619 Loss: 0.15670221876450582\n",
            "Epoch: 620 Loss: 0.15658460333067908\n",
            "Epoch: 621 Loss: 0.15646728303991414\n",
            "Epoch: 622 Loss: 0.15635025674287564\n",
            "Epoch: 623 Loss: 0.15623352329625018\n",
            "Epoch: 624 Loss: 0.15611708156270718\n",
            "Epoch: 625 Loss: 0.15600093041085944\n",
            "Epoch: 626 Loss: 0.15588506871522445\n",
            "Epoch: 627 Loss: 0.15576949535618587\n",
            "Epoch: 628 Loss: 0.1556542092199548\n",
            "Epoch: 629 Loss: 0.1555392091985327\n",
            "Epoch: 630 Loss: 0.15542449418967286\n",
            "Epoch: 631 Loss: 0.1553100630968435\n",
            "Epoch: 632 Loss: 0.15519591482919048\n",
            "Epoch: 633 Loss: 0.15508204830150077\n",
            "Epoch: 634 Loss: 0.1549684624341658\n",
            "Epoch: 635 Loss: 0.15485515615314496\n",
            "Epoch: 636 Loss: 0.15474212838993015\n",
            "Epoch: 637 Loss: 0.15462937808150987\n",
            "Epoch: 638 Loss: 0.1545169041703337\n",
            "Epoch: 639 Loss: 0.15440470560427746\n",
            "Epoch: 640 Loss: 0.1542927813366082\n",
            "Epoch: 641 Loss: 0.15418113032594957\n",
            "Epoch: 642 Loss: 0.15406975153624786\n",
            "Epoch: 643 Loss: 0.15395864393673733\n",
            "Epoch: 644 Loss: 0.15384780650190696\n",
            "Epoch: 645 Loss: 0.1537372382114668\n",
            "Epoch: 646 Loss: 0.15362693805031447\n",
            "Epoch: 647 Loss: 0.15351690500850249\n",
            "Epoch: 648 Loss: 0.15340713808120507\n",
            "Epoch: 649 Loss: 0.15329763626868623\n",
            "Epoch: 650 Loss: 0.15318839857626676\n",
            "Epoch: 651 Loss: 0.1530794240142929\n",
            "Epoch: 652 Loss: 0.15297071159810402\n",
            "Epoch: 653 Loss: 0.15286226034800154\n",
            "Epoch: 654 Loss: 0.15275406928921703\n",
            "Epoch: 655 Loss: 0.1526461374518819\n",
            "Epoch: 656 Loss: 0.15253846387099596\n",
            "Epoch: 657 Loss: 0.15243104758639703\n",
            "Epoch: 658 Loss: 0.15232388764273064\n",
            "Epoch: 659 Loss: 0.15221698308941986\n",
            "Epoch: 660 Loss: 0.15211033298063517\n",
            "Epoch: 661 Loss: 0.15200393637526516\n",
            "Epoch: 662 Loss: 0.1518977923368868\n",
            "Epoch: 663 Loss: 0.15179189993373624\n",
            "Epoch: 664 Loss: 0.1516862582386796\n",
            "Epoch: 665 Loss: 0.15158086632918472\n",
            "Epoch: 666 Loss: 0.15147572328729178\n",
            "Epoch: 667 Loss: 0.15137082819958564\n",
            "Epoch: 668 Loss: 0.1512661801571674\n",
            "Epoch: 669 Loss: 0.15116177825562593\n",
            "Epoch: 670 Loss: 0.1510576215950112\n",
            "Epoch: 671 Loss: 0.15095370927980561\n",
            "Epoch: 672 Loss: 0.15085004041889735\n",
            "Epoch: 673 Loss: 0.150746614125553\n",
            "Epoch: 674 Loss: 0.15064342951739068\n",
            "Epoch: 675 Loss: 0.15054048571635323\n",
            "Epoch: 676 Loss: 0.15043778184868162\n",
            "Epoch: 677 Loss: 0.15033531704488876\n",
            "Epoch: 678 Loss: 0.15023309043973326\n",
            "Epoch: 679 Loss: 0.15013110117219336\n",
            "Epoch: 680 Loss: 0.15002934838544113\n",
            "Epoch: 681 Loss: 0.14992783122681735\n",
            "Epoch: 682 Loss: 0.1498265488478055\n",
            "Epoch: 683 Loss: 0.14972550040400673\n",
            "Epoch: 684 Loss: 0.149624685055115\n",
            "Epoch: 685 Loss: 0.1495241019648922\n",
            "Epoch: 686 Loss: 0.14942375030114335\n",
            "Epoch: 687 Loss: 0.14932362923569195\n",
            "Epoch: 688 Loss: 0.14922373794435623\n",
            "Epoch: 689 Loss: 0.14912407560692448\n",
            "Epoch: 690 Loss: 0.1490246414071313\n",
            "Epoch: 691 Loss: 0.14892543453263374\n",
            "Epoch: 692 Loss: 0.1488264541749878\n",
            "Epoch: 693 Loss: 0.14872769952962495\n",
            "Epoch: 694 Loss: 0.14862916979582877\n",
            "Epoch: 695 Loss: 0.14853086417671182\n",
            "Epoch: 696 Loss: 0.14843278187919293\n",
            "Epoch: 697 Loss: 0.14833492211397414\n",
            "Epoch: 698 Loss: 0.14823728409551823\n",
            "Epoch: 699 Loss: 0.14813986704202628\n",
            "Epoch: 700 Loss: 0.1480426701754154\n",
            "Epoch: 701 Loss: 0.1479456927212964\n",
            "Epoch: 702 Loss: 0.14784893390895198\n",
            "Epoch: 703 Loss: 0.14775239297131512\n",
            "Epoch: 704 Loss: 0.14765606914494678\n",
            "Epoch: 705 Loss: 0.14755996167001517\n",
            "Epoch: 706 Loss: 0.14746406979027385\n",
            "Epoch: 707 Loss: 0.14736839275304067\n",
            "Epoch: 708 Loss: 0.14727292980917686\n",
            "Epoch: 709 Loss: 0.14717768021306593\n",
            "Epoch: 710 Loss: 0.14708264322259304\n",
            "Epoch: 711 Loss: 0.1469878180991243\n",
            "Epoch: 712 Loss: 0.14689320410748644\n",
            "Epoch: 713 Loss: 0.1467988005159462\n",
            "Epoch: 714 Loss: 0.14670460659619056\n",
            "Epoch: 715 Loss: 0.14661062162330643\n",
            "Epoch: 716 Loss: 0.1465168448757608\n",
            "Epoch: 717 Loss: 0.1464232756353811\n",
            "Epoch: 718 Loss: 0.14632991318733518\n",
            "Epoch: 719 Loss: 0.14623675682011258\n",
            "Epoch: 720 Loss: 0.14614380582550454\n",
            "Epoch: 721 Loss: 0.14605105949858482\n",
            "Epoch: 722 Loss: 0.14595851713769115\n",
            "Epoch: 723 Loss: 0.1458661780444057\n",
            "Epoch: 724 Loss: 0.14577404152353662\n",
            "Epoch: 725 Loss: 0.1456821068830991\n",
            "Epoch: 726 Loss: 0.14559037343429726\n",
            "Epoch: 727 Loss: 0.14549884049150513\n",
            "Epoch: 728 Loss: 0.14540750737224892\n",
            "Epoch: 729 Loss: 0.14531637339718848\n",
            "Epoch: 730 Loss: 0.1452254378900993\n",
            "Epoch: 731 Loss: 0.14513470017785493\n",
            "Epoch: 732 Loss: 0.14504415959040876\n",
            "Epoch: 733 Loss: 0.1449538154607765\n",
            "Epoch: 734 Loss: 0.14486366712501866\n",
            "Epoch: 735 Loss: 0.14477371392222324\n",
            "Epoch: 736 Loss: 0.14468395519448818\n",
            "Epoch: 737 Loss: 0.14459439028690443\n",
            "Epoch: 738 Loss: 0.14450501854753847\n",
            "Epoch: 739 Loss: 0.14441583932741595\n",
            "Epoch: 740 Loss: 0.14432685198050418\n",
            "Epoch: 741 Loss: 0.144238055863696\n",
            "Epoch: 742 Loss: 0.14414945033679294\n",
            "Epoch: 743 Loss: 0.14406103476248847\n",
            "Epoch: 744 Loss: 0.14397280850635197\n",
            "Epoch: 745 Loss: 0.14388477093681246\n",
            "Epoch: 746 Loss: 0.14379692142514197\n",
            "Epoch: 747 Loss: 0.1437092593454401\n",
            "Epoch: 748 Loss: 0.14362178407461784\n",
            "Epoch: 749 Loss: 0.14353449499238147\n",
            "Epoch: 750 Loss: 0.14344739148121713\n",
            "Epoch: 751 Loss: 0.14336047292637522\n",
            "Epoch: 752 Loss: 0.1432737387158546\n",
            "Epoch: 753 Loss: 0.14318718824038743\n",
            "Epoch: 754 Loss: 0.1431008208934239\n",
            "Epoch: 755 Loss: 0.1430146360711166\n",
            "Epoch: 756 Loss: 0.1429286331723061\n",
            "Epoch: 757 Loss: 0.14284281159850531\n",
            "Epoch: 758 Loss: 0.1427571707538849\n",
            "Epoch: 759 Loss: 0.1426717100452583\n",
            "Epoch: 760 Loss: 0.14258642888206738\n",
            "Epoch: 761 Loss: 0.1425013266763673\n",
            "Epoch: 762 Loss: 0.14241640284281246\n",
            "Epoch: 763 Loss: 0.1423316567986419\n",
            "Epoch: 764 Loss: 0.1422470879636649\n",
            "Epoch: 765 Loss: 0.142162695760247\n",
            "Epoch: 766 Loss: 0.14207847961329545\n",
            "Epoch: 767 Loss: 0.14199443895024566\n",
            "Epoch: 768 Loss: 0.14191057320104702\n",
            "Epoch: 769 Loss: 0.1418268817981491\n",
            "Epoch: 770 Loss: 0.1417433641764877\n",
            "Epoch: 771 Loss: 0.1416600197734716\n",
            "Epoch: 772 Loss: 0.14157684802896853\n",
            "Epoch: 773 Loss: 0.14149384838529197\n",
            "Epoch: 774 Loss: 0.14141102028718772\n",
            "Epoch: 775 Loss: 0.1413283631818204\n",
            "Epoch: 776 Loss: 0.14124587651876047\n",
            "Epoch: 777 Loss: 0.14116355974997097\n",
            "Epoch: 778 Loss: 0.14108141232979451\n",
            "Epoch: 779 Loss: 0.14099943371494028\n",
            "Epoch: 780 Loss: 0.14091762336447108\n",
            "Epoch: 781 Loss: 0.1408359807397907\n",
            "Epoch: 782 Loss: 0.1407545053046312\n",
            "Epoch: 783 Loss: 0.14067319652504015\n",
            "Epoch: 784 Loss: 0.14059205386936802\n",
            "Epoch: 785 Loss: 0.14051107680825603\n",
            "Epoch: 786 Loss: 0.14043026481462328\n",
            "Epoch: 787 Loss: 0.14034961736365514\n",
            "Epoch: 788 Loss: 0.1402691339327904\n",
            "Epoch: 789 Loss: 0.14018881400170916\n",
            "Epoch: 790 Loss: 0.1401086570523213\n",
            "Epoch: 791 Loss: 0.140028662568754\n",
            "Epoch: 792 Loss: 0.1399488300373398\n",
            "Epoch: 793 Loss: 0.13986915894660523\n",
            "Epoch: 794 Loss: 0.13978964878725844\n",
            "Epoch: 795 Loss: 0.1397102990521781\n",
            "Epoch: 796 Loss: 0.13963110923640143\n",
            "Epoch: 797 Loss: 0.13955207883711263\n",
            "Epoch: 798 Loss: 0.1394732073536317\n",
            "Epoch: 799 Loss: 0.13939449428740294\n",
            "Epoch: 800 Loss: 0.13931593914198326\n",
            "Epoch: 801 Loss: 0.13923754142303177\n",
            "Epoch: 802 Loss: 0.13915930063829787\n",
            "Epoch: 803 Loss: 0.13908121629761036\n",
            "Epoch: 804 Loss: 0.13900328791286645\n",
            "Epoch: 805 Loss: 0.138925514998021\n",
            "Epoch: 806 Loss: 0.13884789706907522\n",
            "Epoch: 807 Loss: 0.13877043364406602\n",
            "Epoch: 808 Loss: 0.1386931242430558\n",
            "Epoch: 809 Loss: 0.1386159683881206\n",
            "Epoch: 810 Loss: 0.13853896560334056\n",
            "Epoch: 811 Loss: 0.13846211541478898\n",
            "Epoch: 812 Loss: 0.1383854173505217\n",
            "Epoch: 813 Loss: 0.13830887094056696\n",
            "Epoch: 814 Loss: 0.13823247571691477\n",
            "Epoch: 815 Loss: 0.13815623121350692\n",
            "Epoch: 816 Loss: 0.1380801369662265\n",
            "Epoch: 817 Loss: 0.13800419251288795\n",
            "Epoch: 818 Loss: 0.13792839739322682\n",
            "Epoch: 819 Loss: 0.1378527511488898\n",
            "Epoch: 820 Loss: 0.13777725332342483\n",
            "Epoch: 821 Loss: 0.137701903462271\n",
            "Epoch: 822 Loss: 0.13762670111274902\n",
            "Epoch: 823 Loss: 0.137551645824051\n",
            "Epoch: 824 Loss: 0.13747673714723135\n",
            "Epoch: 825 Loss: 0.13740197463519635\n",
            "Epoch: 826 Loss: 0.13732735784269537\n",
            "Epoch: 827 Loss: 0.13725288632631052\n",
            "Epoch: 828 Loss: 0.13717855964444794\n",
            "Epoch: 829 Loss: 0.13710437735732786\n",
            "Epoch: 830 Loss: 0.13703033902697542\n",
            "Epoch: 831 Loss: 0.13695644421721126\n",
            "Epoch: 832 Loss: 0.1368826924936426\n",
            "Epoch: 833 Loss: 0.13680908342365355\n",
            "Epoch: 834 Loss: 0.1367356165763964\n",
            "Epoch: 835 Loss: 0.13666229152278242\n",
            "Epoch: 836 Loss: 0.13658910783547265\n",
            "Epoch: 837 Loss: 0.13651606508886915\n",
            "Epoch: 838 Loss: 0.13644316285910627\n",
            "Epoch: 839 Loss: 0.1363704007240411\n",
            "Epoch: 840 Loss: 0.13629777826324568\n",
            "Epoch: 841 Loss: 0.13622529505799733\n",
            "Epoch: 842 Loss: 0.1361529506912704\n",
            "Epoch: 843 Loss: 0.1360807447477277\n",
            "Epoch: 844 Loss: 0.13600867681371168\n",
            "Epoch: 845 Loss: 0.13593674647723603\n",
            "Epoch: 846 Loss: 0.13586495332797727\n",
            "Epoch: 847 Loss: 0.13579329695726586\n",
            "Epoch: 848 Loss: 0.1357217769580787\n",
            "Epoch: 849 Loss: 0.13565039292502992\n",
            "Epoch: 850 Loss: 0.13557914445436306\n",
            "Epoch: 851 Loss: 0.1355080311439428\n",
            "Epoch: 852 Loss: 0.13543705259324665\n",
            "Epoch: 853 Loss: 0.13536620840335714\n",
            "Epoch: 854 Loss: 0.1352954981769531\n",
            "Epoch: 855 Loss: 0.1352249215183024\n",
            "Epoch: 856 Loss: 0.13515447803325342\n",
            "Epoch: 857 Loss: 0.13508416732922754\n",
            "Epoch: 858 Loss: 0.13501398901521058\n",
            "Epoch: 859 Loss: 0.1349439427017459\n",
            "Epoch: 860 Loss: 0.13487402800092588\n",
            "Epoch: 861 Loss: 0.13480424452638431\n",
            "Epoch: 862 Loss: 0.134734591893289\n",
            "Epoch: 863 Loss: 0.13466506971833395\n",
            "Epoch: 864 Loss: 0.13459567761973149\n",
            "Epoch: 865 Loss: 0.13452641521720501\n",
            "Epoch: 866 Loss: 0.1344572821319817\n",
            "Epoch: 867 Loss: 0.13438827798678435\n",
            "Epoch: 868 Loss: 0.13431940240582446\n",
            "Epoch: 869 Loss: 0.13425065501479505\n",
            "Epoch: 870 Loss: 0.13418203544086257\n",
            "Epoch: 871 Loss: 0.13411354331266034\n",
            "Epoch: 872 Loss: 0.13404517826028095\n",
            "Epoch: 873 Loss: 0.13397693991526913\n",
            "Epoch: 874 Loss: 0.13390882791061445\n",
            "Epoch: 875 Loss: 0.13384084188074458\n",
            "Epoch: 876 Loss: 0.1337729814615177\n",
            "Epoch: 877 Loss: 0.13370524629021588\n",
            "Epoch: 878 Loss: 0.13363763600553785\n",
            "Epoch: 879 Loss: 0.1335701502475921\n",
            "Epoch: 880 Loss: 0.1335027886578901\n",
            "Epoch: 881 Loss: 0.13343555087933923\n",
            "Epoch: 882 Loss: 0.133368436556236\n",
            "Epoch: 883 Loss: 0.13330144533425936\n",
            "Epoch: 884 Loss: 0.1332345768604639\n",
            "Epoch: 885 Loss: 0.13316783078327296\n",
            "Epoch: 886 Loss: 0.13310120675247228\n",
            "Epoch: 887 Loss: 0.13303470441920306\n",
            "Epoch: 888 Loss: 0.13296832343595588\n",
            "Epoch: 889 Loss: 0.13290206345656308\n",
            "Epoch: 890 Loss: 0.13283592413619352\n",
            "Epoch: 891 Loss: 0.1327699051313454\n",
            "Epoch: 892 Loss: 0.13270400609983965\n",
            "Epoch: 893 Loss: 0.13263822670081402\n",
            "Epoch: 894 Loss: 0.13257256659471656\n",
            "Epoch: 895 Loss: 0.13250702544329915\n",
            "Epoch: 896 Loss: 0.132441602909611\n",
            "Epoch: 897 Loss: 0.1323762986579932\n",
            "Epoch: 898 Loss: 0.13231111235407156\n",
            "Epoch: 899 Loss: 0.13224604366475107\n",
            "Epoch: 900 Loss: 0.1321810922582093\n",
            "Epoch: 901 Loss: 0.13211625780389066\n",
            "Epoch: 902 Loss: 0.1320515399725002\n",
            "Epoch: 903 Loss: 0.1319869384359974\n",
            "Epoch: 904 Loss: 0.13192245286759033\n",
            "Epoch: 905 Loss: 0.13185808294172965\n",
            "Epoch: 906 Loss: 0.13179382833410264\n",
            "Epoch: 907 Loss: 0.13172968872162752\n",
            "Epoch: 908 Loss: 0.13166566378244696\n",
            "Epoch: 909 Loss: 0.13160175319592296\n",
            "Epoch: 910 Loss: 0.13153795664263063\n",
            "Epoch: 911 Loss: 0.13147427380435261\n",
            "Epoch: 912 Loss: 0.13141070436407318\n",
            "Epoch: 913 Loss: 0.13134724800597253\n",
            "Epoch: 914 Loss: 0.13128390441542143\n",
            "Epoch: 915 Loss: 0.13122067327897508\n",
            "Epoch: 916 Loss: 0.13115755428436784\n",
            "Epoch: 917 Loss: 0.13109454712050778\n",
            "Epoch: 918 Loss: 0.13103165147747053\n",
            "Epoch: 919 Loss: 0.13096886704649452\n",
            "Epoch: 920 Loss: 0.13090619351997493\n",
            "Epoch: 921 Loss: 0.13084363059145865\n",
            "Epoch: 922 Loss: 0.1307811779556384\n",
            "Epoch: 923 Loss: 0.1307188353083478\n",
            "Epoch: 924 Loss: 0.13065660234655568\n",
            "Epoch: 925 Loss: 0.13059447876836106\n",
            "Epoch: 926 Loss: 0.13053246427298754\n",
            "Epoch: 927 Loss: 0.1304705585607781\n",
            "Epoch: 928 Loss: 0.13040876133319018\n",
            "Epoch: 929 Loss: 0.13034707229278994\n",
            "Epoch: 930 Loss: 0.13028549114324744\n",
            "Epoch: 931 Loss: 0.1302240175893315\n",
            "Epoch: 932 Loss: 0.13016265133690444\n",
            "Epoch: 933 Loss: 0.13010139209291696\n",
            "Epoch: 934 Loss: 0.13004023956540317\n",
            "Epoch: 935 Loss: 0.1299791934634755\n",
            "Epoch: 936 Loss: 0.12991825349731992\n",
            "Epoch: 937 Loss: 0.12985741937819043\n",
            "Epoch: 938 Loss: 0.12979669081840467\n",
            "Epoch: 939 Loss: 0.12973606753133862\n",
            "Epoch: 940 Loss: 0.129675549231422\n",
            "Epoch: 941 Loss: 0.12961513563413307\n",
            "Epoch: 942 Loss: 0.12955482645599403\n",
            "Epoch: 943 Loss: 0.12949462141456616\n",
            "Epoch: 944 Loss: 0.1294345202284449\n",
            "Epoch: 945 Loss: 0.12937452261725524\n",
            "Epoch: 946 Loss: 0.12931462830164708\n",
            "Epoch: 947 Loss: 0.12925483700329002\n",
            "Epoch: 948 Loss: 0.12919514844486932\n",
            "Epoch: 949 Loss: 0.12913556235008078\n",
            "Epoch: 950 Loss: 0.12907607844362634\n",
            "Epoch: 951 Loss: 0.1290166964512094\n",
            "Epoch: 952 Loss: 0.12895741609953026\n",
            "Epoch: 953 Loss: 0.12889823711628143\n",
            "Epoch: 954 Loss: 0.1288391592301434\n",
            "Epoch: 955 Loss: 0.1287801821707797\n",
            "Epoch: 956 Loss: 0.12872130566883283\n",
            "Epoch: 957 Loss: 0.12866252945591963\n",
            "Epoch: 958 Loss: 0.12860385326462673\n",
            "Epoch: 959 Loss: 0.1285452768285063\n",
            "Epoch: 960 Loss: 0.12848679988207182\n",
            "Epoch: 961 Loss: 0.12842842216079323\n",
            "Epoch: 962 Loss: 0.12837014340109293\n",
            "Epoch: 963 Loss: 0.12831196334034164\n",
            "Epoch: 964 Loss: 0.1282538817168537\n",
            "Epoch: 965 Loss: 0.128195898269883\n",
            "Epoch: 966 Loss: 0.12813801273961883\n",
            "Epoch: 967 Loss: 0.12808022486718146\n",
            "Epoch: 968 Loss: 0.12802253439461814\n",
            "Epoch: 969 Loss: 0.12796494106489859\n",
            "Epoch: 970 Loss: 0.12790744462191136\n",
            "Epoch: 971 Loss: 0.12785004481045925\n",
            "Epoch: 972 Loss: 0.12779274137625565\n",
            "Epoch: 973 Loss: 0.12773553406591973\n",
            "Epoch: 974 Loss: 0.12767842262697315\n",
            "Epoch: 975 Loss: 0.12762140680783565\n",
            "Epoch: 976 Loss: 0.12756448635782097\n",
            "Epoch: 977 Loss: 0.127507661027133\n",
            "Epoch: 978 Loss: 0.12745093056686185\n",
            "Epoch: 979 Loss: 0.12739429472897976\n",
            "Epoch: 980 Loss: 0.12733775326633703\n",
            "Epoch: 981 Loss: 0.12728130593265854\n",
            "Epoch: 982 Loss: 0.1272249524825396\n",
            "Epoch: 983 Loss: 0.12716869267144185\n",
            "Epoch: 984 Loss: 0.12711252625568978\n",
            "Epoch: 985 Loss: 0.12705645299246682\n",
            "Epoch: 986 Loss: 0.12700047263981143\n",
            "Epoch: 987 Loss: 0.12694458495661337\n",
            "Epoch: 988 Loss: 0.12688878970260986\n",
            "Epoch: 989 Loss: 0.1268330866383819\n",
            "Epoch: 990 Loss: 0.12677747552535068\n",
            "Epoch: 991 Loss: 0.12672195612577342\n",
            "Epoch: 992 Loss: 0.12666652820274021\n",
            "Epoch: 993 Loss: 0.12661119152017014\n",
            "Epoch: 994 Loss: 0.12655594584280747\n",
            "Epoch: 995 Loss: 0.12650079093621822\n",
            "Epoch: 996 Loss: 0.12644572656678657\n",
            "Epoch: 997 Loss: 0.1263907525017109\n",
            "Epoch: 998 Loss: 0.12633586850900086\n",
            "Epoch: 999 Loss: 0.12628107435747327\n",
            "Epoch: 1000 Loss: 0.12622636981674867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "sb5H7kgEuyWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = np.asarray([1, 5.1,\t3.5,\t1.4,\t0.2])"
      ],
      "metadata": {
        "id": "NksSdjltmhsb"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = np.dot(weights.T, x_test)\n",
        "num = np.exp(z)\n",
        "den = np.sum(num)\n",
        "y_hat = num/den"
      ],
      "metadata": {
        "id": "YmoPVz5tm5Xp"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOFfs9cHqkhP",
        "outputId": "fee8a266-b3ea-48a6-8918-4df8a8162171"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.91260390e-01, 8.73960525e-03, 4.73932712e-09])"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ktUUwN1r5NU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}